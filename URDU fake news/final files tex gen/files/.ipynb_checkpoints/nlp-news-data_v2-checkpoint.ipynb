{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-10T17:29:34.793547Z",
     "iopub.status.busy": "2024-06-10T17:29:34.792660Z",
     "iopub.status.idle": "2024-06-10T17:29:35.981934Z",
     "shell.execute_reply": "2024-06-10T17:29:35.981138Z",
     "shell.execute_reply.started": "2024-06-10T17:29:34.793513Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the datasets\n",
    "fake_df = pd.read_csv('/kaggle/input/fake-news-dataset/Fake.csv')#[['text', 'label']]\n",
    "true_df = pd.read_csv('/kaggle/input/fake-news-dataset/True.csv')#[['text', 'label']]\n",
    "\n",
    "# Add 'label' column and assign values\n",
    "fake_df['label'] = 0  # 0 for fake news\n",
    "true_df['label'] = 1  # 1 for true news\n",
    "\n",
    "# Select only the 'text' and 'label' columns\n",
    "fake_df = fake_df[['text', 'label']]\n",
    "true_df = true_df[['text', 'label']]\n",
    "\n",
    "# Combine the datasets\n",
    "combined_df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:29:38.311202Z",
     "iopub.status.busy": "2024-06-10T17:29:38.310357Z",
     "iopub.status.idle": "2024-06-10T17:29:38.317487Z",
     "shell.execute_reply": "2024-06-10T17:29:38.316402Z",
     "shell.execute_reply.started": "2024-06-10T17:29:38.311161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T16:48:08.137190Z",
     "iopub.status.busy": "2024-06-10T16:48:08.136797Z",
     "iopub.status.idle": "2024-06-10T16:48:08.154767Z",
     "shell.execute_reply": "2024-06-10T16:48:08.153795Z",
     "shell.execute_reply.started": "2024-06-10T16:48:08.137152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President-elect Do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON (Reuters) - Congress should launch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Barack Hussein Obama tours around the count...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Oliver absolutely humiliated Mitch McConn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It s no secret Americans have been demonstrati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  WASHINGTON (Reuters) - U.S. President-elect Do...      1\n",
       "1  WASHINGTON (Reuters) - Congress should launch ...      1\n",
       "2  As Barack Hussein Obama tours around the count...      0\n",
       "3  John Oliver absolutely humiliated Mitch McConn...      0\n",
       "4  It s no secret Americans have been demonstrati...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T16:49:18.171518Z",
     "iopub.status.busy": "2024-06-10T16:49:18.170594Z",
     "iopub.status.idle": "2024-06-10T16:49:18.185906Z",
     "shell.execute_reply": "2024-06-10T16:49:18.184915Z",
     "shell.execute_reply.started": "2024-06-10T16:49:18.171485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Value Counts:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "null_counts = combined_df.isnull().sum()\n",
    "print(\"Null Value Counts:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T16:49:41.421381Z",
     "iopub.status.busy": "2024-06-10T16:49:41.421029Z",
     "iopub.status.idle": "2024-06-10T16:49:41.437501Z",
     "shell.execute_reply": "2024-06-10T16:49:41.436245Z",
     "shell.execute_reply.started": "2024-06-10T16:49:41.421353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows with null values\n",
    "combined_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T16:49:42.672328Z",
     "iopub.status.busy": "2024-06-10T16:49:42.671580Z",
     "iopub.status.idle": "2024-06-10T16:49:42.686508Z",
     "shell.execute_reply": "2024-06-10T16:49:42.685488Z",
     "shell.execute_reply.started": "2024-06-10T16:49:42.672294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Value Counts After Removing:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if null values are removed\n",
    "null_counts_after = combined_df.isnull().sum()\n",
    "print(\"Null Value Counts After Removing:\")\n",
    "print(null_counts_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T16:55:47.806699Z",
     "iopub.status.busy": "2024-06-10T16:55:47.805880Z",
     "iopub.status.idle": "2024-06-10T16:55:48.089129Z",
     "shell.execute_reply": "2024-06-10T16:55:48.088079Z",
     "shell.execute_reply.started": "2024-06-10T16:55:47.806666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Sample Preprocessed Text:\n",
      "0    washington  reuters   us presidentelect donald...\n",
      "1    washington  reuters   congress launch bipartis...\n",
      "2    barack hussein obama tours around country tryi...\n",
      "3    john oliver absolutely humiliated mitch mcconn...\n",
      "4    secret americans demonstrating complete lack i...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join tokens back\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing function to the 'text' column\n",
    "combined_df=combined_df.head(50)\n",
    "combined_df['text'] = combined_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Print sample preprocessed text\n",
    "print(\"Sample Preprocessed Text:\")\n",
    "print(combined_df['text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T16:58:11.061566Z",
     "iopub.status.busy": "2024-06-10T16:58:11.060639Z",
     "iopub.status.idle": "2024-06-10T16:58:11.067092Z",
     "shell.execute_reply": "2024-06-10T16:58:11.066172Z",
     "shell.execute_reply.started": "2024-06-10T16:58:11.061532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:06:17.659456Z",
     "iopub.status.busy": "2024-06-10T17:06:17.659055Z",
     "iopub.status.idle": "2024-06-10T17:06:17.695497Z",
     "shell.execute_reply": "2024-06-10T17:06:17.694602Z",
     "shell.execute_reply.started": "2024-06-10T17:06:17.659426Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop blank rows if any\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Select a desired number of rows\n",
    "desired_rows = 1000  # Change this to your desired number of rows\n",
    "combined_df_subset = combined_df.head(desired_rows)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(combined_df_subset['text']).toarray()\n",
    "\n",
    "# Encode labels from combined_df_subset\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(combined_df_subset['label'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:06:27.202170Z",
     "iopub.status.busy": "2024-06-10T17:06:27.201788Z",
     "iopub.status.idle": "2024-06-10T17:06:27.223283Z",
     "shell.execute_reply": "2024-06-10T17:06:27.222481Z",
     "shell.execute_reply.started": "2024-06-10T17:06:27.202141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize and train AdaBoost classifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = ada.predict(X_test)\n",
    "print(\"AdaBoost Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:06:34.251693Z",
     "iopub.status.busy": "2024-06-10T17:06:34.251330Z",
     "iopub.status.idle": "2024-06-10T17:06:34.452422Z",
     "shell.execute_reply": "2024-06-10T17:06:34.451441Z",
     "shell.execute_reply.started": "2024-06-10T17:06:34.251667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GBM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train GBM classifier\n",
    "gbm = GradientBoostingClassifier(n_estimators=100)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(\"GBM Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:06:38.575140Z",
     "iopub.status.busy": "2024-06-10T17:06:38.574307Z",
     "iopub.status.idle": "2024-06-10T17:06:38.914234Z",
     "shell.execute_reply": "2024-06-10T17:06:38.913320Z",
     "shell.execute_reply.started": "2024-06-10T17:06:38.575107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBM\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize and train XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:08:20.206151Z",
     "iopub.status.busy": "2024-06-10T17:08:20.205175Z",
     "iopub.status.idle": "2024-06-10T17:08:28.194327Z",
     "shell.execute_reply": "2024-06-10T17:08:28.193404Z",
     "shell.execute_reply.started": "2024-06-10T17:08:20.206116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4375 - loss: 0.6942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718039305.345994     544 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.4375 - loss: 0.6942 - val_accuracy: 0.7500 - val_loss: 0.6055\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5625 - loss: 0.6116 - val_accuracy: 0.7500 - val_loss: 0.5978\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9688 - loss: 0.4983 - val_accuracy: 0.7500 - val_loss: 0.6037\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9688 - loss: 0.3828 - val_accuracy: 0.7500 - val_loss: 0.5990\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9688 - loss: 0.2802 - val_accuracy: 0.7500 - val_loss: 0.5786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.5000 - loss: 0.6719\n",
      "4-Layer CNN Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# CNN 4 layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Tokenizing and padding sequences\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(combined_df['text'])\n",
    "X_seq = tokenizer.texts_to_sequences(combined_df['text'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Train-test split for CNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build 4-layer CNN model\n",
    "model_4 = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_4.summary()\n",
    "\n",
    "# Train the model\n",
    "model_4.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_4.evaluate(X_test, y_test)\n",
    "print(f'4-Layer CNN Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:08:54.426808Z",
     "iopub.status.busy": "2024-06-10T17:08:54.426110Z",
     "iopub.status.idle": "2024-06-10T17:09:00.923975Z",
     "shell.execute_reply": "2024-06-10T17:09:00.923091Z",
     "shell.execute_reply.started": "2024-06-10T17:08:54.426774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.5000 - loss: 0.6935 - val_accuracy: 0.7500 - val_loss: 0.6838\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8125 - loss: 0.6719 - val_accuracy: 0.7500 - val_loss: 0.6682\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6875 - loss: 0.6594 - val_accuracy: 0.7500 - val_loss: 0.6547\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6363 - val_accuracy: 0.7500 - val_loss: 0.6384\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6875 - loss: 0.5899 - val_accuracy: 0.7500 - val_loss: 0.6256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - accuracy: 0.6000 - loss: 0.6595\n",
      "6-Layer CNN Accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "# CNN 6 layers\n",
    "# Build 6-layer CNN model\n",
    "model_6 = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, 5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_6.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_6.summary()\n",
    "\n",
    "# Train the model\n",
    "model_6.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_6.evaluate(X_test, y_test)\n",
    "print(f'6-Layer CNN Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:35:32.328007Z",
     "iopub.status.busy": "2024-06-10T17:35:32.327236Z",
     "iopub.status.idle": "2024-06-10T17:35:51.633940Z",
     "shell.execute_reply": "2024-06-10T17:35:51.625369Z",
     "shell.execute_reply.started": "2024-06-10T17:35:32.327977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Error processing text at index 0: 'Series' object has no attribute 'append'\n",
      "Error processing text at index 1: 'Series' object has no attribute 'append'\n",
      "Error processing text at index 2: 'Series' object has no attribute 'append'\n",
      "Error processing text at index 3: 'Series' object has no attribute 'append'\n",
      "Error generating text for input: NAIROBI/MOGADISHU (Reuters) - The size and methods...: index out of range in self\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 71\u001b[0m, in \u001b[0;36mgenerate_and_add_texts_to_dataset\u001b[0;34m(model, tokenizer, texts, labels, label, max_new_tokens, subset_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     68\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(generate_text_gpt2, model, tokenizer, text, max_new_tokens)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts[:subset_size]\n\u001b[1;32m     70\u001b[0m ]\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(as_completed(futures)):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 113\u001b[0m\n\u001b[1;32m    110\u001b[0m subset_size \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m100\u001b[39m \u001b[38;5;66;03m# Process only 100 records for faster execution\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Generate new texts based on original texts and add them to the dataset\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m texts, labels \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_and_add_texts_to_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m texts, labels \u001b[38;5;241m=\u001b[39m generate_and_add_texts_to_dataset(model, tokenizer, texts, labels, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, subset_size\u001b[38;5;241m=\u001b[39msubset_size)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Verify the new dataset size\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[75], line 66\u001b[0m, in \u001b[0;36mgenerate_and_add_texts_to_dataset\u001b[0;34m(model, tokenizer, texts, labels, label, max_new_tokens, subset_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_and_add_texts_to_dataset\u001b[39m(model, tokenizer, texts, labels, label, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, subset_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     65\u001b[0m     new_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     67\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     68\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(generate_text_gpt2, model, tokenizer, text, max_new_tokens)\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts[:subset_size]\n\u001b[1;32m     70\u001b[0m         ]\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(as_completed(futures)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating text for input: Will this FINALLY be the straw that breaks the cam...: index out of range in self\n",
      "Error generating text for input: THIS IS SO IMPORTANT! The transcript and video  be...: index out of range in self\n",
      "Error generating text for input:  In response to the establishment media s contrive...: index out of range in self\n",
      "Error generating text for input: ANKARA/BEIRUT (Reuters) - Syrian rebel fighters ar...: index out of range in self\n",
      "Error generating text for input: How is a man with ties to a US based terror organi...: index out of range in self\n",
      "Error generating text for input: BRUSSELS (Reuters) - When Theresa May visits Bruss...: index out of range in self\n",
      "Error generating text for input: (Reuters) - Following is the full text of former F...: index out of range in self\n",
      "Error generating text for input: Everyone suspected the sketchy Steele Dossier was ...: index out of range in self\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "def load_datasets(true_path, fake_path):\n",
    "    texts =combined_df['text']\n",
    "    labels = combined_df['label']\n",
    "    return texts, labels\n",
    "\n",
    "def create_dataloader(texts, tokenizer, max_length, batch_size):\n",
    "    dataset = TextDataset(texts, tokenizer, max_length)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def generate_text_gpt2(model, tokenizer, prompt, max_new_tokens=50):\n",
    "    try:\n",
    "        inputs = tokenizer.encode(prompt, return_tensors='pt', add_special_tokens=True, max_length=1024, truncation=True)\n",
    "        attention_mask = torch.ones(inputs.shape)\n",
    "        \n",
    "        # Check tensor dimensions and values before moving to device\n",
    "        if inputs.shape[1] > 1024:\n",
    "            raise ValueError(f\"Input sequence length exceeds the maximum length of 1024 tokens: {inputs.shape[1]}\")\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        outputs = model.generate(inputs, attention_mask=attention_mask, max_new_tokens=max_new_tokens, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating text for input: {prompt[:50]}...: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_and_add_texts_to_dataset(model, tokenizer, texts, labels, label, max_new_tokens=50, subset_size=100):\n",
    "    new_texts = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(generate_text_gpt2, model, tokenizer, text, max_new_tokens)\n",
    "            for text in texts[:subset_size]\n",
    "        ]\n",
    "        for idx, future in enumerate(as_completed(futures)):\n",
    "            try:\n",
    "                generated_text = future.result()\n",
    "                if generated_text:\n",
    "                    new_texts.append(generated_text)\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Skipped text at index {idx} due to generation error.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text at index {idx}: {e}\")\n",
    "    texts.extend(new_texts)\n",
    "    return texts, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Paths to the datasets\n",
    "        true_path = '/kaggle/input/fake-news-dataset/True.csv'\n",
    "        fake_path = '/kaggle/input/fake-news-dataset/Fake.csv'\n",
    "\n",
    "        # Load datasets\n",
    "        texts, labels = load_datasets(true_path, fake_path)\n",
    "\n",
    "        # Initialize tokenizer\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        max_length = 128\n",
    "\n",
    "        # Create DataLoader\n",
    "        batch_size = 16\n",
    "        dataloader = create_dataloader(texts, tokenizer, max_length, batch_size)\n",
    "\n",
    "        # Ensure using CPU for debugging\n",
    "        device = torch.device('cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Initialize the model\n",
    "        model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Process a controlled subset of data\n",
    "        subset_size =  100 # Process only 100 records for faster execution\n",
    "\n",
    "        # Generate new texts based on original texts and add them to the dataset\n",
    "        texts, labels = generate_and_add_texts_to_dataset(model, tokenizer, texts, labels, label=1, max_new_tokens=50, subset_size=subset_size)\n",
    "        texts, labels = generate_and_add_texts_to_dataset(model, tokenizer, texts, labels, label=0, max_new_tokens=50, subset_size=subset_size)\n",
    "\n",
    "        # Verify the new dataset size\n",
    "        print(f\"Total texts: {len(texts)}\")\n",
    "        print(f\"Total labels: {len(labels)}\")\n",
    "\n",
    "        # Create DataLoader with updated dataset\n",
    "        dataloader = create_dataloader(texts, tokenizer, max_length, batch_size)\n",
    "\n",
    "        # Convert to DataFrame to display\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        display(df.head())  # Display the first few rows of the updated dataset\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:34:47.987742Z",
     "iopub.status.busy": "2024-06-10T17:34:47.986977Z",
     "iopub.status.idle": "2024-06-10T17:34:47.995743Z",
     "shell.execute_reply": "2024-06-10T17:34:47.994802Z",
     "shell.execute_reply.started": "2024-06-10T17:34:47.987711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newly generated data\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:34:14.366581Z",
     "iopub.status.busy": "2024-06-10T17:34:14.365675Z",
     "iopub.status.idle": "2024-06-10T17:34:14.831326Z",
     "shell.execute_reply": "2024-06-10T17:34:14.830497Z",
     "shell.execute_reply.started": "2024-06-10T17:34:14.366547Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop blank rows if any\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Select a desired number of rows\n",
    "desired_rows = 1000  # Change this to your desired number of rows\n",
    "df = df.head(desired_rows)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['text']).toarray()\n",
    "\n",
    "# Encode labels from combined_df_subset\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['label'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:34:21.058228Z",
     "iopub.status.busy": "2024-06-10T17:34:21.057525Z",
     "iopub.status.idle": "2024-06-10T17:34:21.067566Z",
     "shell.execute_reply": "2024-06-10T17:34:21.066599Z",
     "shell.execute_reply.started": "2024-06-10T17:34:21.058197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:33:02.203360Z",
     "iopub.status.busy": "2024-06-10T17:33:02.202636Z",
     "iopub.status.idle": "2024-06-10T17:33:02.236286Z",
     "shell.execute_reply": "2024-06-10T17:33:02.235338Z",
     "shell.execute_reply.started": "2024-06-10T17:33:02.203328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize and train AdaBoost classifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = ada.predict(X_test)\n",
    "print(\"AdaBoost Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T17:33:05.791686Z",
     "iopub.status.busy": "2024-06-10T17:33:05.791087Z",
     "iopub.status.idle": "2024-06-10T17:33:05.875654Z",
     "shell.execute_reply": "2024-06-10T17:33:05.874509Z",
     "shell.execute_reply.started": "2024-06-10T17:33:05.791652Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize and train GBM classifier\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gbm \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Predictions and evaluation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m gbm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:440\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    437\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 440\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_y(y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:1232\u001b[0m, in \u001b[0;36mGradientBoostingClassifier._validate_y\u001b[0;34m(self, y, sample_weight)\u001b[0m\n\u001b[1;32m   1230\u001b[0m n_trim_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(np\u001b[38;5;241m.\u001b[39mbincount(y, sample_weight))\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_trim_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class after sample_weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrimmed classes with zero weights, while a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimum of 2 classes are required.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m n_trim_classes\n\u001b[1;32m   1236\u001b[0m     )\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# expose n_classes_ attribute\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
     ]
    }
   ],
   "source": [
    "# GBM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train GBM classifier\n",
    "gbm = GradientBoostingClassifier(n_estimators=100)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(\"GBM Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-10T16:31:03.751228Z",
     "iopub.status.idle": "2024-06-10T16:31:03.751548Z",
     "shell.execute_reply": "2024-06-10T16:31:03.751407Z",
     "shell.execute_reply.started": "2024-06-10T16:31:03.751394Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBM\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize and train XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-10T16:31:03.754271Z",
     "iopub.status.idle": "2024-06-10T16:31:03.754580Z",
     "shell.execute_reply": "2024-06-10T16:31:03.754442Z",
     "shell.execute_reply.started": "2024-06-10T16:31:03.754429Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN 4 layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Tokenizing and padding sequences\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['text'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Train-test split for CNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build 4-layer CNN model\n",
    "model_4 = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_4.summary()\n",
    "\n",
    "# Train the model\n",
    "model_4.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_4.evaluate(X_test, y_test)\n",
    "print(f'4-Layer CNN Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-10T16:31:03.758133Z",
     "iopub.status.idle": "2024-06-10T16:31:03.758451Z",
     "shell.execute_reply": "2024-06-10T16:31:03.758310Z",
     "shell.execute_reply.started": "2024-06-10T16:31:03.758297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating text for input: WASHINGTON (Reuters) - The U.S. Supreme Court on M...: index out of range in self\n",
      "Error generating text for input: WASHINGTON/NEW YORK (Reuters) - A series of tweets...: index out of range in self\n"
     ]
    }
   ],
   "source": [
    "# CNN 6 layers\n",
    "# Build 6-layer CNN model\n",
    "model_6 = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, 5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_6.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_6.summary()\n",
    "\n",
    "# Train the model\n",
    "model_6.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_6.evaluate(X_test, y_test)\n",
    "print(f'6-Layer CNN Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5101245,
     "sourceId": 8539408,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
